{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd778a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # PyTorch kütüphanesini içe aktarır.\n",
    "from torch.utils.data import DataLoader, Subset, Dataset  # Veri yükleme ve işleme için gerekli sınıfları içe aktarır.\n",
    "from torchvision.datasets import EMNIST  # EMNIST veri kümesini içe aktarır.\n",
    "from torchvision import transforms  # Görüntü dönüşümleri için gerekli sınıfları içe aktarır.\n",
    "from diffusers import UNet2DModel, DDPMScheduler  # Diffüzyon modelleri için gerekli sınıfları içe aktarır.\n",
    "from torch.optim import AdamW  # AdamW optimizasyon algoritmasını içe aktarır.\n",
    "from accelerate import Accelerator  # Hızlandırıcıyı içe aktarır (GPU/TPU kullanımı için).\n",
    "from PIL import Image  # Görüntü işleme için Pillow kütüphanesini içe aktarır.\n",
    "from torchmetrics.image.ssim import StructuralSimilarityIndexMeasure  # SSIM (Yapısal Benzerlik Ölçüsü) metriğini içe aktarır.\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance  # FID (Fréchet Inception Distance) metriğini içe aktarır.\n",
    "from torchmetrics.image.inception import InceptionScore  # Inception Score metriğini içe aktarır.\n",
    "import torch.nn.functional as F  # Fonksiyonel sinir ağı araçlarını içe aktarır.\n",
    "from tqdm.auto import tqdm  # Döngüler için ilerleme çubuğu gösterimini içe aktarır.\n",
    "import os  # İşletim sistemi etkileşimleri için os modülünü içe aktarır.\n",
    "import json  # JSON verisiyle çalışmak için json modülünü içe aktarır.\n",
    "import matplotlib.pyplot as plt  # Grafik çizmek için matplotlib kütüphanesini içe aktarır.\n",
    "import pandas as pd  # Veri analizi için pandas kütüphanesini içe aktarır.\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau  # Öğrenme oranını ayarlamak için ReduceLROnPlateau'yu içe aktarır.\n",
    "# === 1. Veri Kümesi Kurulumu ===\n",
    "\n",
    "class RemapLabels(Dataset):  # Etiketleri yeniden eşlemek için özel bir Dataset sınıfı tanımlar.\n",
    "    def __init__(self, subset, label_map):  # Sınıfın kurucu metodu.\n",
    "        self.subset = subset  # Alt küme verisini saklar.\n",
    "        self.label_map = label_map  # Etiket eşleme sözlüğünü saklar.\n",
    "\n",
    "    def __getitem__(self, idx):  # Veri kümesinden bir öğe almak için gerekli olan getitem metodunu tanımlar.\n",
    "        x, y = self.subset[idx]  # Alt kümeden veriyi alır.\n",
    "        return x, self.label_map[y]  # Yeniden eşlenmiş etiketle birlikte veriyi döndürür.\n",
    "\n",
    "    def __len__(self):  # Veri kümesinin uzunluğunu döndüren len metodunu tanımlar.\n",
    "        return len(self.subset)  # Alt kümenin uzunluğunu döndürür.\n",
    "\n",
    "\n",
    "def get_letter_emnist_dataset():  # Harf EMNIST veri kümesini almak için bir fonksiyon tanımlar.\n",
    "    full_dataset = EMNIST(  # Tam EMNIST veri kümesini yükler.\n",
    "        \"./data\",  # Veri kümesinin saklanacağı dizin.\n",
    "        split=\"byclass\",  # Veri kümesinin sınıflara göre ayrılacağını belirtir.\n",
    "        train=True,  # Eğitim verisi olarak yükleneceğini belirtir.\n",
    "        download=True,  # Veri kümesinin indirilmesi gerektiğini belirtir.\n",
    "        transform=transforms.Compose([  # Görüntü dönüşümlerini tanımlar.\n",
    "            transforms.ToTensor(),  # Görüntüyü tensöre dönüştürür.\n",
    "            transforms.Normalize([0.5], [0.5])  # Görüntüyü normalize eder.\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    valid_labels = list(range(10, 62))   # A-Z (10-35), a-z (36-61) aralığındaki geçerli etiketleri tanımlar.\n",
    "    indices = [i for i, (_, label) in enumerate(full_dataset) if label in valid_labels]  # Geçerli etiketlere sahip verilerin indekslerini bulur.\n",
    "    label_map = {orig: new for new, orig in enumerate(valid_labels)}  # Orijinal etiketlerden yeni etiketlere bir eşleme oluşturur.\n",
    "    subset = Subset(full_dataset, indices)  # Tam veri kümesinden geçerli etiketlere sahip bir alt küme oluşturur.\n",
    "\n",
    "    return RemapLabels(subset, label_map), [chr(i) for i in range(65, 91)] + [chr(i) for i in range(97, 123)]  # Yeniden etiketlenmiş alt küme ve sınıf etiketlerini döndürür.\n",
    "\n",
    "\n",
    "dataset, class_labels = get_letter_emnist_dataset()  # Veri kümesini ve sınıf etiketlerini alır.\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)  # Veri yükleyiciyi oluşturur.\n",
    "num_classes = len(class_labels)  # Sınıf sayısını belirler.\n",
    "\n",
    "os.makedirs(\"emnist_diffusion_model\", exist_ok=True)  # Modelin kaydedileceği dizini oluşturur.\n",
    "with open(\"emnist_diffusion_model/class_map.json\", \"w\") as f:  # Sınıf etiketlerini bir JSON dosyasına kaydeder.\n",
    "    json.dump(class_labels, f)  # Sınıf etiketlerini JSON formatında dosyaya yazar.\n",
    "\n",
    "# === 2. Model Yapılandırması ===\n",
    "\n",
    "noise_scheduler = DDPMScheduler(  # Gürültü zamanlamasını tanımlar.\n",
    "    num_train_timesteps=1000,  # Eğitim için kullanılacak zaman adımlarını belirtir.\n",
    "    beta_schedule=\"linear\",  # Beta zamanlama tipini belirtir (gürültü ekleme şeması).\n",
    "    beta_start=0.0001,  # Beta'nın başlangıç değerini belirtir.\n",
    "    beta_end=0.02  # Beta'nın bitiş değerini belirtir.\n",
    ")\n",
    "\n",
    "model = UNet2DModel(  # UNet 2D modelini tanımlar.\n",
    "    sample_size=28,  # Giriş görüntüsünün boyutunu belirtir.\n",
    "    in_channels=1,  # Giriş görüntüsünün kanal sayısını belirtir (gri tonlamalı için 1).\n",
    "    out_channels=1,  # Çıkış görüntüsünün kanal sayısını belirtir.\n",
    "    layers_per_block=2,   # Her bloktaki katman sayısını belirtir.\n",
    "    block_out_channels=(32, 64, 128),  # Her blokun çıkış kanallarını belirtir.\n",
    "    down_block_types=(\"DownBlock2D\", \"DownBlock2D\", \"DownBlock2D\"),  # Aşağı örnekleme blok tiplerini belirtir.\n",
    "    up_block_types=(\"UpBlock2D\", \"UpBlock2D\", \"UpBlock2D\"),  # Yukarı örnekleme blok tiplerini belirtir.\n",
    "    class_embed_type=\"timestep\",  # Sınıf gömme tipini belirtir.\n",
    "    num_class_embeds=num_classes,  # Sınıf gömme sayısını belirtir (sınıf sayısı).\n",
    ")\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=1e-6)  # AdamW optimizasyon algoritmasını tanımlar.\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max', patience=3, factor=0.5, verbose=True)  # Öğrenme oranı düşürücüyü tanımlar.\n",
    "\n",
    "# === 3. Hızlandırıcı Kurulumu ===\n",
    "\n",
    "accelerator = Accelerator(  # Hızlandırıcıyı tanımlar.\n",
    "    mixed_precision=\"fp16\",  # Karışık duyarlıklı eğitim kullanacağını belirtir.\n",
    "    gradient_accumulation_steps=4,  # Gradyan birikim adımlarını belirtir.\n",
    "    log_with=\"tensorboard\",  # TensorBoard ile loglama yapacağını belirtir.\n",
    "    project_dir=\"emnist_diffusion_model\"  # TensorBoard loglarının saklanacağı dizini belirtir.\n",
    ")\n",
    "\n",
    "model, optimizer, dataloader = accelerator.prepare(model, optimizer, dataloader)  # Modeli, optimize ediciyi ve veri yükleyiciyi hızlandırıcı için hazırlar.\n",
    "\n",
    "# === 4. Kontrol Noktası Yükleme ===\n",
    "\n",
    "checkpoint_path = \"emnist_diffusion_model/epoch_47\"  # Yüklenecek kontrol noktasının yolunu belirtir.\n",
    "start_epoch = 0  # Başlangıç epoch'unu tanımlar.\n",
    "if os.path.exists(checkpoint_path):  # Eğer belirtilen yolda bir kontrol noktası varsa:\n",
    "    accelerator.load_state(checkpoint_path)  # Kontrol noktasını yükler.\n",
    "    start_epoch = 47  # Başlangıç epoch'unu günceller.\n",
    "    print(f\"Checkpoint from epoch 47 successfully loaded!\")  # Başarı mesajını yazdırır.\n",
    "else:  # Eğer kontrol noktası bulunamazsa:\n",
    "    print(f\"Checkpoint from epoch 47 not found, starting from scratch.\")  # Bilgi mesajını yazdırır.\n",
    "\n",
    "ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0).to(accelerator.device)  # SSIM metriğini tanımlar ve hızlandırıcı cihazına taşır.\n",
    "fid_metric = FrechetInceptionDistance(feature=64).to(accelerator.device)  # FID metriğini tanımlar ve hızlandırıcı cihazına taşır.\n",
    "is_metric = InceptionScore().to(accelerator.device)  # IS metriğini tanımlar ve hızlandırıcı cihazına taşır.\n",
    "\n",
    "\n",
    "\n",
    "def estimate_neurons(model):  # Modeldeki toplam nöron sayısını tahmin eden bir fonksiyon tanımlar.\n",
    "    total_neurons = 0  # Toplam nöron sayısını saklamak için bir değişkeni başlatır.\n",
    "    for name, module in model.named_modules():  # Modelin katmanları arasında döngü yapar.\n",
    "        if isinstance(module, torch.nn.Conv2d):  # Eğer katman bir Convolutional katmansa:\n",
    "            total_neurons += module.out_channels * module.kernel_size[0] * module.kernel_size[1]  # Nöron sayısını hesaplar ve toplama ekler.\n",
    "        elif isinstance(module, torch.nn.Linear):  # Eğer katman bir Fully Connected katmansa:\n",
    "            total_neurons += module.out_features  # Nöron sayısını toplama ekler.\n",
    "        elif isinstance(module, torch.nn.Embedding):  # Eğer katman bir Embedding katmansa:\n",
    "            total_neurons += module.embedding_dim  # Nöron sayısını toplama ekler.\n",
    "        elif isinstance(module, torch.nn.GroupNorm):\n",
    "            total_neurons += module.num_channels * 2\n",
    "\n",
    "    return total_neurons  # Toplam nöron sayısını döndürür.\n",
    "\n",
    "num_neurons = estimate_neurons(accelerator.unwrap_model(model))  # Modeldeki toplam nöron sayısını hesaplar.\n",
    "print(f\"Estimated total number of neurons in the model: {num_neurons:,}\")  # Sonucu yazdırır.\n",
    "\n",
    "\n",
    "# === 5. Örnekleme ve Değerlendirme ===\n",
    "\n",
    "def generate_batch_samples(model, scheduler, num_classes, device):  # Belirli bir batch için örnekler üreten bir fonksiyon tanımlar.\n",
    "    model.eval()  # Modeli değerlendirme moduna geçirir.\n",
    "    # Her sınıf için bir örnek oluşturur, sıralı olarak (0'dan num_classes-1'e kadar)\n",
    "    all_labels = torch.arange(num_classes, device=device)\n",
    "    noise = torch.randn((num_classes, 1, 28, 28), device=device)\n",
    "\n",
    "    for t in tqdm(reversed(range(scheduler.num_train_timesteps)), desc=\"Sampling\"):\n",
    "        t_batch = torch.full((num_classes,), t, device=device)\n",
    "        with torch.no_grad():\n",
    "            noise_pred = model(noise, t_batch, all_labels).sample\n",
    "        noise = scheduler.step(noise_pred, t, noise).prev_sample\n",
    "\n",
    "    images = (noise.clamp(-1, 1) + 1) * 0.5\n",
    "    return images, all_labels\n",
    "\n",
    "def get_label_ordered_real_images(dataloader, num_classes):\n",
    "    \"\"\"Collects one example of a real image for each class, ordered by label (from 0 to num_classes-1)\"\"\"\n",
    "    ordered = {}\n",
    "    for images, labels in dataloader:\n",
    "        for img, label in zip(images, labels):\n",
    "            label = label.item()\n",
    "            if label not in ordered:\n",
    "                ordered[label] = img\n",
    "            if len(ordered) == num_classes:\n",
    "                break\n",
    "        if len(ordered) == num_classes:\n",
    "            break\n",
    "\n",
    "    # Ensure there is exactly one example for each class, in order\n",
    "    ordered_images = [ordered[i] for i in range(num_classes)]\n",
    "    return torch.stack(ordered_images)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def show_label_aligned_images(fake_images, fake_labels, real_images, class_labels, epoch_tag=\"pre_training\"):  # Etiket hizalı görüntüleri gösteren bir fonksiyon tanımlar.\n",
    "    num_classes = len(class_labels)\n",
    "\n",
    "    fig, axes = plt.subplots(2, num_classes, figsize=(num_classes, 2))\n",
    "    for i in range(num_classes):\n",
    "        # Both fake and real images are already ordered (from 0 to num_classes-1)\n",
    "        # Show the real image\n",
    "        axes[0, i].imshow(real_images[i][0].cpu(), cmap=\"gray\")\n",
    "        axes[0, i].axis(\"off\")\n",
    "        axes[0, i].set_title(class_labels[i], fontsize=6)\n",
    "\n",
    "        # Show the fake image (same index because they are ordered)\n",
    "        axes[1, i].imshow(fake_images[i][0].cpu(), cmap=\"gray\")\n",
    "        axes[1, i].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(f\"Real (Top) vs Fake (Bottom) - {epoch_tag}\", y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def save_individual_samples(fake_images, fake_labels, class_labels, epoch):  # Üretilen örnekleri ayrı ayrı kaydeden bir fonksiyon tanımlar.\n",
    "    os.makedirs(f\"emnist_diffusion_model/samples/epoch_{epoch}\", exist_ok=True)\n",
    "\n",
    "    for img, label in zip(fake_images, fake_labels):\n",
    "        label = label.item()\n",
    "        char = class_labels[label]\n",
    "        case = 'u' if char.isupper() else 'l'\n",
    "        filename = f\"emnist_diffusion_model/samples/epoch_{epoch}/{epoch}_{char}_{case}.png\"\n",
    "\n",
    "        img_pil = transforms.ToPILImage()(img.cpu())\n",
    "        img_pil.save(filename)\n",
    "\n",
    "def evaluate_metrics(fake_images, fake_labels, real_images, ssim_metric, fid_metric, is_metric, device):  # Üretilen görüntülerin kalitesini değerlendiren bir fonksiyon tanımlar.\n",
    "    # Metrikler için gerçek ve sahte görüntüleri hazırlar\n",
    "    real_images = (real_images + 1) / 2.0\n",
    "    if real_images.ndim == 3:\n",
    "        real_images = real_images[:, None]\n",
    "    if fake_images.ndim == 3:\n",
    "        fake_images = fake_images[:, None]\n",
    "\n",
    "    # SSIM hesaplaması\n",
    "    ssim_score = ssim_metric(fake_images.to(device), real_images.to(device)).item()\n",
    "\n",
    "    # FID ve IS için hazırla\n",
    "    fake_images_metric = preprocess_for_metrics(fake_images)\n",
    "    real_images_metric = preprocess_for_metrics(real_images)\n",
    "\n",
    "    # Metrikleri sıfırla\n",
    "    fid_metric.reset()\n",
    "    is_metric.reset()\n",
    "\n",
    "    # FID'yi hesapla\n",
    "    fid_metric.update(real_images_metric.to(device), real=True)\n",
    "    fid_metric.update(fake_images_metric.to(device), real=False)\n",
    "    fid_score = fid_metric.compute().item()\n",
    "\n",
    "    # IS'yi hesapla\n",
    "    is_metric.update(fake_images_metric.to(device))\n",
    "    is_score, _ = is_metric.compute()\n",
    "    is_score = is_score.item()\n",
    "\n",
    "    return ssim_score, fid_score, is_score\n",
    "\n",
    "def preprocess_for_metrics(imgs):  # Görüntüleri metrik hesaplamaları için önceden işleyen bir fonksiyon tanımlar.\n",
    "    # [0, 255] aralığına ölçekle, uint8'e dönüştür\n",
    "    imgs = ((imgs + 1) * 127.5).clamp(0, 255).to(torch.uint8)\n",
    "\n",
    "    # 1 kanallıdan 3 kanallıya dönüştür\n",
    "    if imgs.shape[1] == 1:\n",
    "        imgs = imgs.repeat(1, 3, 1, 1)\n",
    "\n",
    "    # 299x299'a yeniden boyutlandır\n",
    "    imgs = F.interpolate(imgs.float(), size=(299, 299), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    return imgs.to(torch.uint8)\n",
    "\n",
    "\n",
    "\n",
    "history = {\n",
    "    \"epoch\": [],\n",
    "    \"loss\": [],\n",
    "    \"ssim\": [],\n",
    "    \"fid\": [],\n",
    "    \"is\": []\n",
    "}\n",
    "\n",
    "\n",
    "# === 6. Eğitim Döngüsü ===\n",
    "\n",
    "num_epochs = 100  # Toplam epoch sayısını tanımlar.\n",
    "save_interval = 5  # Modeli ne sıklıkla kaydedeceğimizi tanımlar.\n",
    "grad_accum_steps = accelerator.gradient_accumulation_steps  # Hızlandırıcıdan gradyan birikim adımı sayısını alır.\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):  # Her epoch için döngü.\n",
    "    model.train()  # Modeli eğitim moduna ayarlar.\n",
    "    total_loss = 0.0  # Epoch için toplam kaybı başlatır.\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\")  # Epoch için bir ilerleme çubuğu oluşturur.\n",
    "\n",
    "    for batch_idx, batch in enumerate(progress_bar):  # Veri yükleyiciden batch'ler arasında döngü yapar.\n",
    "        if batch_idx % 100 == 0 and torch.cuda.is_available():  # Her 100 batch'te bir, eğer CUDA varsa:\n",
    "            torch.cuda.empty_cache()  # Bellek sorunlarını önlemek için CUDA önbelleğini temizler.\n",
    "\n",
    "        clean_images, labels = batch  # Batch'ten temiz görüntüleri ve etiketleri alır.\n",
    "        clean_images = clean_images.to(accelerator.device)  # Görüntüleri hızlandırıcı cihazına (GPU/TPU) taşır.\n",
    "        labels = labels.to(accelerator.device)  # Etiketleri hızlandırıcı cihazına taşır.\n",
    "\n",
    "        noise = torch.randn_like(clean_images)  # Görüntülerle aynı boyutta rastgele gürültü oluşturur.\n",
    "        timesteps = torch.randint(0, noise_scheduler.num_train_timesteps, (clean_images.size(0),), device=clean_images.device)  # Her görüntü için rastgele zaman adımları oluşturur.\n",
    "        noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)  # Gürültülü görüntüleri oluşturur.\n",
    "        noise_pred = model(noisy_images, timesteps, labels).sample  # Modeli gürültülü görüntülerle çalıştırarak gürültü tahminini alır.\n",
    "        loss = torch.nn.functional.mse_loss(noise_pred, noise)  # Tahmin edilen gürültü ile gerçek gürültü arasındaki ortalama kare hatasını hesaplar.\n",
    "        total_loss += loss.item()  # Epoch'un toplam kaybına mevcut batch'in kaybını ekler.\n",
    "\n",
    "        accelerator.backward(loss)  # Gradyanları hesaplamak için geri yayılımı gerçekleştirir.\n",
    "        if (batch_idx + 1) % grad_accum_steps == 0:  # Eğer işlenen batch sayısı gradyan birikim adımlarına eşitse:\n",
    "            accelerator.clip_grad_norm_(model.parameters(), 1.0)  # Gradyanların çok büyümesini önlemek için kırpar.\n",
    "            optimizer.step()  # Modeli güncellemek için bir optimizasyon adımı gerçekleştirir.\n",
    "            optimizer.zero_grad()  # Gradyanları sıfırlar.\n",
    "\n",
    "        avg_loss = total_loss / (batch_idx + 1)  # Mevcut batch'e kadar olan ortalama kaybı hesaplar.\n",
    "        progress_bar.set_postfix(loss=loss.item(), avg_loss=avg_loss)  # İlerleme çubuğunu mevcut kayıp ve ortalama kayıpla günceller.\n",
    "\n",
    "    # Epoch sonunda değerlendirme\n",
    "    model_eval = accelerator.unwrap_model(model)  # Modeli hızlandırıcıdan çıkarır.\n",
    "\n",
    "    # Her epoch'ta örnek oluştur\n",
    "    fake_images, fake_labels = generate_batch_samples(model_eval, noise_scheduler, num_classes, accelerator.device)  # Örnek görüntüler oluşturur.\n",
    "    real_images = get_label_ordered_real_images(dataloader, num_classes)\n",
    "\n",
    "    # Oluşturulan örnekleri kaydet\n",
    "    save_individual_samples(fake_images, fake_labels, class_labels, epoch + 1)\n",
    "\n",
    "    # Oluşturulan örnekleri gerçek görüntülerle karşılaştır\n",
    "    print(f\"\\n[Epoch {epoch + 1}] Real vs Generated Samples:\")\n",
    "    show_label_aligned_images(fake_images, fake_labels, real_images, class_labels, epoch_tag=f\"epoch_{epoch + 1}\")\n",
    "\n",
    "    # Metrikleri değerlendir\n",
    "    ssim_score, fid_score, is_score = evaluate_metrics(\n",
    "        fake_images, fake_labels, real_images,\n",
    "        ssim_metric, fid_metric, is_metric,\n",
    "        accelerator.device\n",
    "    )\n",
    "\n",
    "    # Geçmişi güncelle\n",
    "    history[\"epoch\"].append(epoch + 1)\n",
    "    history[\"loss\"].append(avg_loss)\n",
    "    history[\"ssim\"].append(ssim_score)\n",
    "    history[\"fid\"].append(fid_score)\n",
    "    history[\"is\"].append(is_score)\n",
    "\n",
    "    print(f\"[Epoch {epoch + 1}] SSIM: {ssim_score:.4f}, FID: {fid_score:.4f}, IS: {is_score:.4f}\")\n",
    "\n",
    "    # Metrikleri CSV dosyasına kaydet\n",
    "    pd.DataFrame(history).to_csv(\"emnist_diffusion_model/training_metrics.csv\", index=False)\n",
    "\n",
    "    scheduler.step(ssim_score)  # Öğrenme oranını SSIM puanına göre ayarlar.\n",
    "\n",
    "    # İlerlemeyi çiz\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history[\"epoch\"], history[\"loss\"], label=\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid()\n",
    "    plt.title(\"Training Loss\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history[\"epoch\"], history[\"ssim\"], label=\"SSIM\", color=\"green\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"SSIM\")\n",
    "    plt.grid()\n",
    "    plt.title(\"SSIM vs Epoch\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(history[\"epoch\"], history[\"fid\"], label=\"FID\", color=\"blue\")\n",
    "    plt.plot(history[\"epoch\"], history[\"is\"], label=\"IS\", color=\"orange\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.title(\"FID & IS vs Epoch\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"emnist_diffusion_model/training_progress_epoch_{epoch + 1}.png\")\n",
    "    plt.close()\n",
    "\n",
    "    if len(history[\"ssim\"]) >= 2 and history[\"ssim\"][-1] < history[\"ssim\"][-2]:\n",
    "        print(\"⚠️ Warning: SSIM has decreased — possible overfitting.\")\n",
    "\n",
    "    accelerator.save_state(output_dir=f\"emnist_diffusion_model/epoch_{epoch + 1}\")  # Modeli kaydeder.\n",
    "\n",
    "accelerator.save_state(output_dir=\"emnist_diffusion_model/final\")  # Son modeli kaydeder.\n",
    "accelerator.end_training()  # Hızlandırıcıyı sonlandırır.\n",
    "\n",
    "print(\"Training completed successfully!\")  # Eğitim tamamlandığında bir mesaj yazdırır.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
